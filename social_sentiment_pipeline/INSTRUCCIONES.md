# üöÄ Instrucciones de Instalaci√≥n y Uso

## Prerrequisitos

1. **Docker Desktop** instalado y corriendo
2. **Credenciales de Twitter API v2** (Bearer Token m√≠nimo)
3. **Git** para clonar el repositorio
4. **8GB RAM** m√≠nimo recomendado

## üîß Configuraci√≥n Inicial

### 1. Configurar Variables de Entorno

```bash
# Copiar archivo de ejemplo
copy .env.example .env

# Editar .env con tus credenciales de Twitter API
notepad .env
```

**Importante:** Debes obtener credenciales de Twitter API en https://developer.twitter.com/

### 2. Iniciar el Pipeline

```bash
# Construir y levantar todos los servicios
docker-compose up -d

# O usar el script de inicio (en Linux/Mac)
# ./scripts/start_pipeline.sh
```

### 3. Verificar Servicios

Espera 2-3 minutos y verifica que todos los servicios est√©n corriendo:

```bash
docker-compose ps
```

## üåê Acceso a Interfaces

Una vez que todos los servicios est√©n corriendo:

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| **Airflow** | http://localhost:8080 | admin / admin |
| **Grafana** | http://localhost:3000 | admin / admin |
| **Kafka UI** | http://localhost:8081 | - |
| **Spark Master** | http://localhost:8082 | - |

## üìä Uso del Pipeline

### 1. Activar DAGs en Airflow

1. Ve a http://localhost:8080
2. Inicia sesi√≥n con admin/admin
3. Activa el DAG `sentiment_analysis_pipeline`
4. El pipeline comenzar√° a procesar tweets autom√°ticamente

### 2. Monitorear en Grafana

1. Ve a http://localhost:3000
2. Inicia sesi√≥n con admin/admin
3. Ve a Dashboards ‚Üí "An√°lisis de Sentimientos en Tiempo Real"
4. Observa m√©tricas en tiempo real

### 3. Verificar Datos en ClickHouse

```bash
# Conectar a ClickHouse
docker-compose exec clickhouse clickhouse-client

# Ver datos procesados
SELECT count() FROM sentiment_db.sentiment_analysis;

# Ver √∫ltimos tweets procesados
SELECT * FROM sentiment_db.sentiment_analysis ORDER BY processing_timestamp DESC LIMIT 10;
```

## üîç Monitoreo y Troubleshooting

### Ver Logs de Servicios

```bash
# Ver logs de todos los servicios
docker-compose logs -f

# Ver logs de un servicio espec√≠fico
docker-compose logs -f kafka
docker-compose logs -f spark-master
docker-compose logs -f airflow-webserver
```

### Verificar Salud de Kafka

```bash
# Listar topics
docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list

# Ver mensajes en topic
docker-compose exec kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic raw_tweets --from-beginning
```

### Reiniciar Servicios

```bash
# Reiniciar un servicio espec√≠fico
docker-compose restart kafka

# Reiniciar todo el pipeline
docker-compose down
docker-compose up -d
```

## üìà An√°lisis de Datos

### Jupyter Notebook

```bash
# Instalar dependencias localmente (opcional)
pip install jupyter pandas matplotlib seaborn clickhouse-driver

# Ejecutar notebook de an√°lisis
jupyter notebook notebooks/exploratory_analysis.ipynb
```

### Generar Reportes

```bash
# Ejecutar reporte de m√©tricas
docker-compose exec airflow-webserver python /opt/airflow/src/utils/metrics_reporter.py
```

## üõë Detener el Pipeline

```bash
# Detener servicios manteniendo datos
docker-compose down

# Detener y eliminar todos los datos
docker-compose down -v

# O usar script (Linux/Mac)
# ./scripts/stop_pipeline.sh
```

## üéØ Casos de Uso

### 1. Monitoreo de Marca
- Configura keywords relacionadas con tu marca en `.env`
- Monitorea sentimientos en tiempo real
- Recibe alertas por sentimientos negativos masivos

### 2. An√°lisis de Eventos
- Cambia keywords para eventos espec√≠ficos
- Analiza reacci√≥n p√∫blica en tiempo real
- Genera reportes post-evento

### 3. Investigaci√≥n de Mercado
- Monitorea competidores y productos
- Analiza tendencias de sentimiento
- Identifica influencers y temas trending

## üîß Personalizaci√≥n

### Cambiar Keywords de B√∫squeda

Edita el archivo `.env`:
```
SEARCH_KEYWORDS=bitcoin,ethereum,tesla,apple,google,tu_marca
```

### Ajustar Intervalos de Procesamiento

En `docker-compose.yml`, modifica variables de entorno:
```yaml
environment:
  PROCESSING_INTERVAL_SECONDS: 30  # Cambiar intervalo
  BATCH_SIZE: 100                  # Cambiar tama√±o de batch
```

### Personalizar Dashboards

1. Ve a Grafana ‚Üí Dashboards
2. Edita el dashboard existente
3. Agrega nuevos paneles y m√©tricas
4. Guarda los cambios

## üìö Recursos Adicionales

- **Twitter API Docs:** https://developer.twitter.com/en/docs/twitter-api
- **Apache Kafka:** https://kafka.apache.org/documentation/
- **Apache Spark:** https://spark.apache.org/docs/latest/
- **ClickHouse:** https://clickhouse.com/docs/
- **Grafana:** https://grafana.com/docs/

## üÜò Soporte

Si encuentras problemas:

1. Verifica que Docker Desktop est√© corriendo
2. Aseg√∫rate de tener las credenciales de Twitter API correctas
3. Revisa los logs con `docker-compose logs -f`
4. Verifica que los puertos no est√©n ocupados por otros servicios
5. Reinicia el pipeline completo si es necesario

## üéâ ¬°Listo!

Tu pipeline de an√°lisis de sentimientos en tiempo real est√° funcionando. Ahora puedes:

- ‚úÖ Procesar miles de tweets por minuto
- ‚úÖ Analizar sentimientos con ML avanzado
- ‚úÖ Visualizar m√©tricas en tiempo real
- ‚úÖ Generar alertas autom√°ticas
- ‚úÖ Crear reportes de an√°lisis

¬°Perfecto para demostrar habilidades de ingenier√≠a de datos moderna!