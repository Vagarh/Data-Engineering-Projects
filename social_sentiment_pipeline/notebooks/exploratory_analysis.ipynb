{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Sentimientos\n",
    "\n",
    "Este notebook contiene análisis exploratorio de los datos de sentimientos procesados por el pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from clickhouse_driver import Client\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a ClickHouse\n",
    "client = Client(\n",
    "    host='localhost',\n",
    "    port=9000,\n",
    "    user='admin',\n",
    "    password='password',\n",
    "    database='sentiment_db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análisis General de Volumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos de las últimas 24 horas\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    toStartOfHour(created_at) as hour,\n",
    "    count() as total_tweets,\n",
    "    countIf(predicted_sentiment = 'positive') as positive,\n",
    "    countIf(predicted_sentiment = 'neutral') as neutral,\n",
    "    countIf(predicted_sentiment = 'negative') as negative\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "GROUP BY hour\n",
    "ORDER BY hour\n",
    "\"\"\"\n",
    "\n",
    "df_hourly = pd.DataFrame(client.execute(query), \n",
    "                        columns=['hour', 'total_tweets', 'positive', 'neutral', 'negative'])\n",
    "df_hourly['hour'] = pd.to_datetime(df_hourly['hour'])\n",
    "df_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar tendencias por hora\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Volumen total\n",
    "ax1.plot(df_hourly['hour'], df_hourly['total_tweets'], marker='o', linewidth=2)\n",
    "ax1.set_title('Volumen de Tweets por Hora', fontsize=16)\n",
    "ax1.set_ylabel('Número de Tweets')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribución de sentimientos\n",
    "ax2.plot(df_hourly['hour'], df_hourly['positive'], marker='o', label='Positivo', color='green')\n",
    "ax2.plot(df_hourly['hour'], df_hourly['neutral'], marker='s', label='Neutral', color='gray')\n",
    "ax2.plot(df_hourly['hour'], df_hourly['negative'], marker='^', label='Negativo', color='red')\n",
    "ax2.set_title('Distribución de Sentimientos por Hora', fontsize=16)\n",
    "ax2.set_ylabel('Número de Tweets')\n",
    "ax2.set_xlabel('Hora')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis de Confianza del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de confianza por sentimiento\n",
    "query_confidence = \"\"\"\n",
    "SELECT \n",
    "    predicted_sentiment,\n",
    "    avg(confidence) as avg_confidence,\n",
    "    quantile(0.5)(confidence) as median_confidence,\n",
    "    min(confidence) as min_confidence,\n",
    "    max(confidence) as max_confidence,\n",
    "    count() as count\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "GROUP BY predicted_sentiment\n",
    "\"\"\"\n",
    "\n",
    "df_confidence = pd.DataFrame(client.execute(query_confidence),\n",
    "                           columns=['sentiment', 'avg_confidence', 'median_confidence', \n",
    "                                  'min_confidence', 'max_confidence', 'count'])\n",
    "print(\"Estadísticas de Confianza por Sentimiento:\")\n",
    "print(df_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análisis de Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relación entre sentimiento y engagement\n",
    "query_engagement = \"\"\"\n",
    "SELECT \n",
    "    predicted_sentiment,\n",
    "    avg(like_count) as avg_likes,\n",
    "    avg(retweet_count) as avg_retweets,\n",
    "    avg(like_count + retweet_count) as avg_total_engagement\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "    AND (like_count > 0 OR retweet_count > 0)\n",
    "GROUP BY predicted_sentiment\n",
    "\"\"\"\n",
    "\n",
    "df_engagement = pd.DataFrame(client.execute(query_engagement),\n",
    "                           columns=['sentiment', 'avg_likes', 'avg_retweets', 'avg_total_engagement'])\n",
    "\n",
    "# Visualizar engagement por sentimiento\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "x = np.arange(len(df_engagement))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, df_engagement['avg_likes'], width, label='Likes', alpha=0.8)\n",
    "ax.bar(x + width/2, df_engagement['avg_retweets'], width, label='Retweets', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Sentimiento')\n",
    "ax.set_ylabel('Engagement Promedio')\n",
    "ax.set_title('Engagement Promedio por Sentimiento')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_engagement['sentiment'])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Palabras Clave Trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top palabras por sentimiento\n",
    "query_words = \"\"\"\n",
    "WITH word_sentiment AS (\n",
    "    SELECT \n",
    "        arrayJoin(extractAll(lower(text), '[a-zA-Z]{4,}')) as word,\n",
    "        predicted_sentiment\n",
    "    FROM sentiment_analysis \n",
    "    WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "        AND length(word) >= 4\n",
    "        AND word NOT IN ('this', 'that', 'with', 'have', 'will', 'from', 'they', 'been', 'were', 'said', 'each', 'which', 'their', 'time', 'would', 'there', 'could', 'other', 'more', 'very', 'what', 'know', 'just', 'first', 'into', 'over', 'think', 'also', 'your', 'work', 'life', 'only', 'can', 'still', 'should', 'after', 'being', 'now', 'made', 'before', 'here', 'through', 'when', 'where', 'much', 'some', 'these', 'many', 'then', 'them', 'well', 'were')\n",
    ")\n",
    "SELECT \n",
    "    word,\n",
    "    predicted_sentiment,\n",
    "    count() as frequency\n",
    "FROM word_sentiment\n",
    "GROUP BY word, predicted_sentiment\n",
    "HAVING frequency >= 3\n",
    "ORDER BY frequency DESC\n",
    "LIMIT 50\n",
    "\"\"\"\n",
    "\n",
    "df_words = pd.DataFrame(client.execute(query_words),\n",
    "                       columns=['word', 'sentiment', 'frequency'])\n",
    "\n",
    "# Top 10 palabras por cada sentimiento\n",
    "for sentiment in ['positive', 'negative', 'neutral']:\n",
    "    top_words = df_words[df_words['sentiment'] == sentiment].head(10)\n",
    "    print(f\"\\nTop 10 palabras - {sentiment.upper()}:\")\n",
    "    for _, row in top_words.iterrows():\n",
    "        print(f\"  {row['word']}: {row['frequency']} menciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis Temporal Detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis por día de la semana\n",
    "query_weekday = \"\"\"\n",
    "SELECT \n",
    "    toDayOfWeek(created_at) as day_of_week,\n",
    "    count() as total_tweets,\n",
    "    avg(confidence) as avg_confidence,\n",
    "    countIf(predicted_sentiment = 'positive') / count() as positive_rate\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 7 DAY\n",
    "GROUP BY day_of_week\n",
    "ORDER BY day_of_week\n",
    "\"\"\"\n",
    "\n",
    "df_weekday = pd.DataFrame(client.execute(query_weekday),\n",
    "                         columns=['day_of_week', 'total_tweets', 'avg_confidence', 'positive_rate'])\n",
    "\n",
    "# Mapear días de la semana\n",
    "day_names = {1: 'Lunes', 2: 'Martes', 3: 'Miércoles', 4: 'Jueves', \n",
    "            5: 'Viernes', 6: 'Sábado', 7: 'Domingo'}\n",
    "df_weekday['day_name'] = df_weekday['day_of_week'].map(day_names)\n",
    "\n",
    "print(\"Análisis por día de la semana:\")\n",
    "print(df_weekday[['day_name', 'total_tweets', 'avg_confidence', 'positive_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen ejecutivo\n",
    "query_summary = \"\"\"\n",
    "SELECT \n",
    "    count() as total_tweets,\n",
    "    countIf(predicted_sentiment = 'positive') / count() * 100 as positive_pct,\n",
    "    countIf(predicted_sentiment = 'negative') / count() * 100 as negative_pct,\n",
    "    avg(confidence) as avg_confidence,\n",
    "    sum(like_count + retweet_count) as total_engagement,\n",
    "    uniq(author_id) as unique_authors\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "\"\"\"\n",
    "\n",
    "summary = client.execute(query_summary)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"📊 RESUMEN EJECUTIVO - ÚLTIMAS 24 HORAS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"📈 Total de tweets procesados: {summary[0]:,}\")\n",
    "print(f\"😊 Sentimiento positivo: {summary[1]:.1f}%\")\n",
    "print(f\"😞 Sentimiento negativo: {summary[2]:.1f}%\")\n",
    "print(f\"🎯 Confianza promedio del modelo: {summary[3]:.3f}\")\n",
    "print(f\"💫 Engagement total: {summary[4]:,}\")\n",
    "print(f\"👥 Autores únicos: {summary[5]:,}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}