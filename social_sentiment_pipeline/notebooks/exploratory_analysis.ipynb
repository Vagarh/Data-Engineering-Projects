{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An치lisis Exploratorio de Sentimientos\n",
    "\n",
    "Este notebook contiene an치lisis exploratorio de los datos de sentimientos procesados por el pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from clickhouse_driver import Client\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configurar visualizaciones\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a ClickHouse\n",
    "client = Client(\n",
    "    host='localhost',\n",
    "    port=9000,\n",
    "    user='admin',\n",
    "    password='password',\n",
    "    database='sentiment_db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. An치lisis General de Volumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener datos de las 칰ltimas 24 horas\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    toStartOfHour(created_at) as hour,\n",
    "    count() as total_tweets,\n",
    "    countIf(predicted_sentiment = 'positive') as positive,\n",
    "    countIf(predicted_sentiment = 'neutral') as neutral,\n",
    "    countIf(predicted_sentiment = 'negative') as negative\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "GROUP BY hour\n",
    "ORDER BY hour\n",
    "\"\"\"\n",
    "\n",
    "df_hourly = pd.DataFrame(client.execute(query), \n",
    "                        columns=['hour', 'total_tweets', 'positive', 'neutral', 'negative'])\n",
    "df_hourly['hour'] = pd.to_datetime(df_hourly['hour'])\n",
    "df_hourly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar tendencias por hora\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Volumen total\n",
    "ax1.plot(df_hourly['hour'], df_hourly['total_tweets'], marker='o', linewidth=2)\n",
    "ax1.set_title('Volumen de Tweets por Hora', fontsize=16)\n",
    "ax1.set_ylabel('N칰mero de Tweets')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuci칩n de sentimientos\n",
    "ax2.plot(df_hourly['hour'], df_hourly['positive'], marker='o', label='Positivo', color='green')\n",
    "ax2.plot(df_hourly['hour'], df_hourly['neutral'], marker='s', label='Neutral', color='gray')\n",
    "ax2.plot(df_hourly['hour'], df_hourly['negative'], marker='^', label='Negativo', color='red')\n",
    "ax2.set_title('Distribuci칩n de Sentimientos por Hora', fontsize=16)\n",
    "ax2.set_ylabel('N칰mero de Tweets')\n",
    "ax2.set_xlabel('Hora')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. An치lisis de Confianza del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An치lisis de confianza por sentimiento\n",
    "query_confidence = \"\"\"\n",
    "SELECT \n",
    "    predicted_sentiment,\n",
    "    avg(confidence) as avg_confidence,\n",
    "    quantile(0.5)(confidence) as median_confidence,\n",
    "    min(confidence) as min_confidence,\n",
    "    max(confidence) as max_confidence,\n",
    "    count() as count\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "GROUP BY predicted_sentiment\n",
    "\"\"\"\n",
    "\n",
    "df_confidence = pd.DataFrame(client.execute(query_confidence),\n",
    "                           columns=['sentiment', 'avg_confidence', 'median_confidence', \n",
    "                                  'min_confidence', 'max_confidence', 'count'])\n",
    "print(\"Estad칤sticas de Confianza por Sentimiento:\")\n",
    "print(df_confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. An치lisis de Engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relaci칩n entre sentimiento y engagement\n",
    "query_engagement = \"\"\"\n",
    "SELECT \n",
    "    predicted_sentiment,\n",
    "    avg(like_count) as avg_likes,\n",
    "    avg(retweet_count) as avg_retweets,\n",
    "    avg(like_count + retweet_count) as avg_total_engagement\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "    AND (like_count > 0 OR retweet_count > 0)\n",
    "GROUP BY predicted_sentiment\n",
    "\"\"\"\n",
    "\n",
    "df_engagement = pd.DataFrame(client.execute(query_engagement),\n",
    "                           columns=['sentiment', 'avg_likes', 'avg_retweets', 'avg_total_engagement'])\n",
    "\n",
    "# Visualizar engagement por sentimiento\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "x = np.arange(len(df_engagement))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, df_engagement['avg_likes'], width, label='Likes', alpha=0.8)\n",
    "ax.bar(x + width/2, df_engagement['avg_retweets'], width, label='Retweets', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Sentimiento')\n",
    "ax.set_ylabel('Engagement Promedio')\n",
    "ax.set_title('Engagement Promedio por Sentimiento')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df_engagement['sentiment'])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Palabras Clave Trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top palabras por sentimiento\n",
    "query_words = \"\"\"\n",
    "WITH word_sentiment AS (\n",
    "    SELECT \n",
    "        arrayJoin(extractAll(lower(text), '[a-zA-Z]{4,}')) as word,\n",
    "        predicted_sentiment\n",
    "    FROM sentiment_analysis \n",
    "    WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "        AND length(word) >= 4\n",
    "        AND word NOT IN ('this', 'that', 'with', 'have', 'will', 'from', 'they', 'been', 'were', 'said', 'each', 'which', 'their', 'time', 'would', 'there', 'could', 'other', 'more', 'very', 'what', 'know', 'just', 'first', 'into', 'over', 'think', 'also', 'your', 'work', 'life', 'only', 'can', 'still', 'should', 'after', 'being', 'now', 'made', 'before', 'here', 'through', 'when', 'where', 'much', 'some', 'these', 'many', 'then', 'them', 'well', 'were')\n",
    ")\n",
    "SELECT \n",
    "    word,\n",
    "    predicted_sentiment,\n",
    "    count() as frequency\n",
    "FROM word_sentiment\n",
    "GROUP BY word, predicted_sentiment\n",
    "HAVING frequency >= 3\n",
    "ORDER BY frequency DESC\n",
    "LIMIT 50\n",
    "\"\"\"\n",
    "\n",
    "df_words = pd.DataFrame(client.execute(query_words),\n",
    "                       columns=['word', 'sentiment', 'frequency'])\n",
    "\n",
    "# Top 10 palabras por cada sentimiento\n",
    "for sentiment in ['positive', 'negative', 'neutral']:\n",
    "    top_words = df_words[df_words['sentiment'] == sentiment].head(10)\n",
    "    print(f\"\\nTop 10 palabras - {sentiment.upper()}:\")\n",
    "    for _, row in top_words.iterrows():\n",
    "        print(f\"  {row['word']}: {row['frequency']} menciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. An치lisis Temporal Detallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An치lisis por d칤a de la semana\n",
    "query_weekday = \"\"\"\n",
    "SELECT \n",
    "    toDayOfWeek(created_at) as day_of_week,\n",
    "    count() as total_tweets,\n",
    "    avg(confidence) as avg_confidence,\n",
    "    countIf(predicted_sentiment = 'positive') / count() as positive_rate\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 7 DAY\n",
    "GROUP BY day_of_week\n",
    "ORDER BY day_of_week\n",
    "\"\"\"\n",
    "\n",
    "df_weekday = pd.DataFrame(client.execute(query_weekday),\n",
    "                         columns=['day_of_week', 'total_tweets', 'avg_confidence', 'positive_rate'])\n",
    "\n",
    "# Mapear d칤as de la semana\n",
    "day_names = {1: 'Lunes', 2: 'Martes', 3: 'Mi칠rcoles', 4: 'Jueves', \n",
    "            5: 'Viernes', 6: 'S치bado', 7: 'Domingo'}\n",
    "df_weekday['day_name'] = df_weekday['day_of_week'].map(day_names)\n",
    "\n",
    "print(\"An치lisis por d칤a de la semana:\")\n",
    "print(df_weekday[['day_name', 'total_tweets', 'avg_confidence', 'positive_rate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resumen y Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar resumen ejecutivo\n",
    "query_summary = \"\"\"\n",
    "SELECT \n",
    "    count() as total_tweets,\n",
    "    countIf(predicted_sentiment = 'positive') / count() * 100 as positive_pct,\n",
    "    countIf(predicted_sentiment = 'negative') / count() * 100 as negative_pct,\n",
    "    avg(confidence) as avg_confidence,\n",
    "    sum(like_count + retweet_count) as total_engagement,\n",
    "    uniq(author_id) as unique_authors\n",
    "FROM sentiment_analysis \n",
    "WHERE created_at >= now() - INTERVAL 24 HOUR\n",
    "\"\"\"\n",
    "\n",
    "summary = client.execute(query_summary)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"游늵 RESUMEN EJECUTIVO - 칔LTIMAS 24 HORAS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"游늳 Total de tweets procesados: {summary[0]:,}\")\n",
    "print(f\"游땕 Sentimiento positivo: {summary[1]:.1f}%\")\n",
    "print(f\"游 Sentimiento negativo: {summary[2]:.1f}%\")\n",
    "print(f\"游꿢 Confianza promedio del modelo: {summary[3]:.3f}\")\n",
    "print(f\"游눪 Engagement total: {summary[4]:,}\")\n",
    "print(f\"游논 Autores 칰nicos: {summary[5]:,}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}